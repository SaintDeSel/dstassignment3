---
title: "dst_2_sam"
output: html_document
---

```{r setup, include=FALSE}
knitr::opts_chunk$set(echo = TRUE)
```

Before we start, we'll load some useful packages:

```{r}
library(tidyverse)
library(naivebayes)
library(caret)
```

Importing the KDD11 dataset:

```{r}
kddata<-read.csv("//Users//samanthawise//Documents//VersionControl//datasciencetoolbox//assignment_1//data//kddcup.data_10_percent") # edit path

kddnames <- read.table("//Users//samanthawise//Documents//VersionControl//datasciencetoolbox//assignment_1//data//kddcup.names",sep=":",skip=1,as.is=T) # edit path

colnames(kddata) <- c(kddnames[,1],"label")

kddata$label <- as.character(kddata$label)
```

We're going to try to predict the protocol type.

```{r}
table(kddata[,"protocol_type"])
table(kddata[,"duration"]==0)
table(kddata[kddata$duration != 0,]$protocol_type)
table(kddata[kddata$duration == 0,]$protocol_type)
```


So there is no zero duration data for the protocol icmp. However for zero duration there is double the amount of icmp then udp. (should we perform log transform on nonzero duration?)

ICMP is a control protocol, meaning that it designed to not carry application data, but rather information about the status of the network itself. 

Both Transmission Control Protocol (TCP) and User Datagram Protocol (UDP) are transportation protocols, they are used to pass the actual data. The main difference between TCP and UDP is that TCP is a connection oriented protocol, it guarantees that all sent packets will reach the destination in the correct order.

UDP, on the other hand, is a connection-less protocol. Communication is datagram oriented, so the integrity is guaranteed only on the single datagram. Datagrams reach destination and can arrive out of order or don't arrive at all. It's generally used for real time communication, where a little percentage of packet loss rate is preferable to the overhead of a TCP connection.

```{r}
trans <- function(x){
  x[,"logduration"]=log10(x[,"duration"])
  x[,"zeroduration"]=(x[,"duration"]==0)
  x
}
kddata2 <- trans(kddata)

kddata2non <- kddata2 %>%
  subset(zeroduration == FALSE) %>%
  mutate(protocol_type = factor(protocol_type)) %>%
  select(duration, protocol_type, count:dst_host_srv_rerror_rate)
  #select(duration, protocol_type, same_srv_rate, diff_srv_rate, srv_diff_host_rate, dst_host_count, dst_host_srv_count, dst_host_same_srv_rate, dst_host_diff_srv_rate, dst_host_same_src_port_rate)


kddata2non_harding <- kddata2non %>%
  mutate(protocol_type = factor(as.numeric(factor(protocol_type)))) #since lvq works on binarised data

kddata2zero <- kddata2 %>%
  subset(zeroduration == TRUE)
  
```

We'll now make a test dataset and a training dataset. First we consider the nonzero duration scenario and we wish to see if we can classify between UDP and TCP:


```{r}
set.seed(1)
n <- dim(kddata2non_harding)[1]
s <- sample(1:n,n/2)
train <- kddata2non_harding[s,]
test <- kddata2non_harding[-s,]
```

Naive Bayes Model

```{r}
#m <- naive_bayes(protocol_type ~ ., data = train)
#m <- naive_bayes(protocol_type ~ ., data = train, laplace = 1)

x_w <- kddata2non %>%
  select(duration, count:dst_host_srv_rerror_rate)
  #select(duration, same_srv_rate:dst_host_same_src_port_rate)

y_w <- kddata2non$protocol_type

model_w <- train(x,y,'naive_bayes',trControl=trainControl(method='cv',number=10))
```

LVQ model

```{r}
x_h <- kddata2non_harding %>%
  select(duration, count:dst_host_srv_rerror_rate)

y_h <- kddata2non_harding$protocol_type

model_h <- train(x_harding,y,'lvq',trControl=trainControl(method='cv',number=10))

```


Making predictions. How many classification errors were made?

Naive Bayes:

```{r}
#predict_naive <- predict(m, test)
#predict_naive_prob <- predict(m, test, type = "prob")
pred_w <- predict(model_w$finalModel,x_w)
confusionMatrix(pred_w, y_w)
```

LVQ

```{r}
require(class)
pred_h <- lvqtest(model_h$finalModel,x_h)
confusionMatrix(pred_h, y)
```

Plotting the features:

```{r}
naive_protocol <- naive_bayes(protocol_type ~ ., data = kddata2non)
plot(naive_protocol)
```

```{r}
lvq_fun <- getModelInfo("lvq")[[1]]
lvq_fun$prob <- function (modelFit, newdata, submodels = NULL)  {
  out <- exp(predict(modelFit, newdata))
  t(apply(out, 1, function(x) x/sum(x)))
}
```



Stacking

```{r}
# Example of Stacking algorithms
# create submodels
library(caret)
library(caretEnsemble)
# control <- trainControl(method="repeatedcv", number=10, repeats=3, savePredictions=TRUE, classProbs=TRUE)
control <- trainControl(method="cv", number=10, classProbs = TRUE)
algorithmList <- c('naive_bayes', 'adaboost')
set.seed(7)
models <- caretList(protocol_type ~., data=kddata2non, trControl=control, methodList=algorithmList)
results <- resamples(models)
summary(results)
dotplot(results)
```
```{r}
# correlation between results
modelCor(results)
splom(results)
```

```{r}
# stack use the random forest algorithm to combine the predictions.
# stackControl <- trainControl(method="repeatedcv", number=10, repeats=3, savePredictions=TRUE, classProbs=TRUE)
stackControl <- trainControl(method="cv", number=10, classProbs = TRUE)
set.seed(7)
stack.rf <- caretStack(models, method="rf", metric="Accuracy", trControl=stackControl)
print(stack.rf)
```

```{r}
# Generate level-one dataset for training the ensemble metalearner
#predDF <- data.frame(pred_w, pred_w)
#modelStack <- train(protocol_type ~ ., data = predDF, method = "rf")
```

